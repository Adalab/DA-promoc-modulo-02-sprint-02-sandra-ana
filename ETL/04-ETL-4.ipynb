{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ataques = pd.read_csv(\"../data/04-tiburon_4.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climas = pd.read_csv(\"../data/00-datos_clima.csv\", index_col= 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming ETL Carga I\n",
    "\n",
    "Es el momento de meter todos nuestros datos en SQL 💪🏽!!! En este ejercicio nos crearemos dos tablas en una BBDD creada por nosotras. Una de las tablas contendrá la información que obtuvimos de los ejercicios de pair programming de Limpieza, es decir, el data set de ataques de tiburones limpito. La segunda tabla tendrá la información obtenida en el ejercicio de pair de ETL 1.\n",
    "\n",
    "📌 Nota Todo lo tendremos que hacer desde jupyter notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cread la BBDD con el nombre de tiburones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cread las tablas de la BBDD:\n",
    "    - Tabla ataques\n",
    "    - Tabla clima"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. BONUS Insertar los datos en las tablas.\n",
    "📌 Nota Esta parte del pair es optativa y no será considerada para la evaluación\n",
    "\n",
    "🚨 En caso de que no tengáis los datos unidos de la sesión anterior, tenéis un csv datos_union_clima_ataques con todos los datos que necesitareis para este ejercicio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una base de datos que se llame Tiburones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función para crear la base de datos\n",
    "def crear_bbdd(nombre_bbdd):\n",
    "\n",
    "    mydb = mysql.connector.connect(\n",
    "      host=\"localhost\",\n",
    "      user=\"root\",\n",
    "      password='AlumnaAdalab' \n",
    "    )\n",
    "    print(\"Conexión realizada con éxito\")\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    try:\n",
    "        mycursor.execute(f\"CREATE DATABASE IF NOT EXISTS {nombre_bbdd};\")\n",
    "        print(mycursor)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión realizada con éxito\n",
      "CMySQLCursor: CREATE DATABASE IF NOT EXISTS tiburones;\n"
     ]
    }
   ],
   "source": [
    "mydb = crear_bbdd(\"tiburones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función para crear las tablas\n",
    "def crear_insertar_tabla(nombre_bbdd, contraseña, query):\n",
    "    \n",
    "    # nos conectamsos con el servidor usando el conector de sql\n",
    "    cnx = mysql.connector.connect(user='root', password=f\"{contraseña}\",\n",
    "                                     host='127.0.0.1', database=f\"{nombre_bbdd}\")\n",
    "    # iniciamos el cursor\n",
    "    mycursor = cnx.cursor()\n",
    "    \n",
    "    # intentamos hacer la query\n",
    "    try: \n",
    "        mycursor.execute(query)\n",
    "        cnx.commit() \n",
    "    # en caso de que podamos ejecutar la query devuelvenos un error para saber en que nos estamos equivocando\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1669 entries, 0 to 1671\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   year      1669 non-null   int64  \n",
      " 1   type      1669 non-null   object \n",
      " 2   country   1669 non-null   object \n",
      " 3   activity  1669 non-null   object \n",
      " 4   age       1669 non-null   float64\n",
      " 5   species   1669 non-null   object \n",
      " 6   month     1669 non-null   object \n",
      " 7   fatal     1669 non-null   object \n",
      " 8   gender    1669 non-null   object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 130.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Hacemos un info para ir viendo los tipos de datos y los nombres de las columnas\n",
    "df_ataques.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la query para crear la tabla ataques\n",
    "tabla_ataques = '''\n",
    "CREATE TABLE IF NOT EXISTS `tiburones`.`ataques` (\n",
    "  `id_ataques` INT NOT NULL AUTO_INCREMENT,\n",
    "  `year` INT NOT NULL,\n",
    "  `type`VARCHAR (225) NOT NULL,\n",
    "  `country` VARCHAR (225) NOT NULL,\n",
    "  `activity` VARCHAR (225) NOT NULL,\n",
    "  `age` FLOAT NOT NULL,\n",
    "  `species_` VARCHAR (225) NOT NULL,\n",
    "  `mes` VARCHAR (45) NOT NULL,\n",
    "  `deceso` VARCHAR (45) NOT NULL,\n",
    "  `genero` VARCHAR (45) NOT NULL,\n",
    "  PRIMARY KEY (`id_ataques`))\n",
    "ENGINE = InnoDB;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320 entries, 0 to 319\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   timepoint          320 non-null    int64  \n",
      " 1   cloudcover         320 non-null    int64  \n",
      " 2   highcloud          320 non-null    int64  \n",
      " 3   midcloud           320 non-null    int64  \n",
      " 4   lowcloud           320 non-null    int64  \n",
      " 5   rh_profile         320 non-null    object \n",
      " 6   wind_profile       320 non-null    object \n",
      " 7   temp2m             320 non-null    int64  \n",
      " 8   lifted_index       320 non-null    int64  \n",
      " 9   rh2m               320 non-null    int64  \n",
      " 10  msl_pressure       320 non-null    int64  \n",
      " 11  prec_type          320 non-null    object \n",
      " 12  prec_amount        320 non-null    int64  \n",
      " 13  snow_depth         320 non-null    int64  \n",
      " 14  wind10m.direction  320 non-null    int64  \n",
      " 15  wind10m.speed      320 non-null    int64  \n",
      " 16  country            320 non-null    object \n",
      " 17  latitud            320 non-null    float64\n",
      " 18  longitud           320 non-null    float64\n",
      "dtypes: float64(2), int64(13), object(4)\n",
      "memory usage: 50.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Hacemos el info para ir viendo los nombres y tipo de datos de las columnas\n",
    "df_climas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la query para crear la tabla clima\n",
    "tabla_clima = '''\n",
    "CREATE TABLE IF NOT EXISTS `tiburones`.`clima` (\n",
    "  `id_clima` INT NOT NULL AUTO_INCREMENT,\n",
    "  `timepoint` INT NOT NULL,\n",
    "  `cloudcover` INT NOT NULL,\n",
    "  `highcloud` INT NOT NULL,\n",
    "  `midcloud` INT NOT NULL,\n",
    "  `lowcloud` INT NOT NULL,\n",
    "  `rh_profile` VARCHAR (45) NOT NULL,\n",
    "  `wind_profile` VARCHAR (45) NOT NULL,\n",
    "  `temp2m` INT NOT NULL,\n",
    "  `lifted_index` INT NOT NULL,\n",
    "  `rh2m` INT NOT NULL,\n",
    "  `msl_pressure` INT NOT NULL,\n",
    "  `prec_type` VARCHAR (45) NOT NULL,\n",
    "  `prec_amount` INT NOT NULL,\n",
    "  `snow_depth` INT NOT NULL,\n",
    "  `wind10m.direction` INT NOT NULL,\n",
    "  `wind10m.speed` INT NOT NULL,\n",
    "  `country` VARCHAR (45) NOT NULL,\n",
    "  `latitud` DECIMAL NOT NULL,\n",
    "  `longitud` DECIMAL NOT NULL,\n",
    "  PRIMARY KEY (`id_clima`))\n",
    "ENGINE = InnoDB;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a la función para crear las dos tablas en nuestra BBD\n",
    "crear_insertar_tabla(\"tiburones\", \"AlumnaAdalab\", tabla_ataques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_insertar_tabla(\"tiburones\", \"AlumnaAdalab\", tabla_clima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al intentar cargar los datos, vemos que tenemos un error por una columna con una comilla de más. Lo reemplazamos por un espacio vacío\n",
    "df_ataques[\"activity\"] = df_ataques[\"activity\"].replace(r'\"', '', regex= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indice, fila in df_ataques.iterrows(): # iteramos por el dataframe.\n",
    "    \n",
    "    # definimos nuestra query, igual que si lo hicieramos en workbench. ⚠️ Como estamos definiendo nuestra query en varias líneas usamos las triples comillas\n",
    "    # lo valores que introduciremos serán los del dataframe que estamos iterando, por lo que usaremos los formats de los strings. \n",
    "    \n",
    "    query_ataques = f\"\"\"\n",
    "            INSERT INTO ataques (year, type, country, activity, age, species_, mes, deceso, genero)\n",
    "            VALUES ( \"{fila['year']}\", \"{fila['type']}\", \"{fila['country']}\", \"{fila['activity']}\", \"{fila['age']}\", \"{fila['species']}\", \"{fila['month']}\", \"{fila['fatal']}\", \"{fila['gender']}\");\n",
    "            \"\"\"\n",
    "    # una vez definida la query llamamos a la función que nos inserta los datos. \n",
    "    crear_insertar_tabla(\"tiburones\", \"AlumnaAdalab\", query_ataques)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8be240dc937e61b542e412c89351978950720d3fde5a0c37c158fb19f149fb89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
