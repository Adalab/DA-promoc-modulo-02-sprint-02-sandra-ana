{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../files/students.csv\", index_col = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming ETL Transformación I\n",
    "\n",
    "Tendréis que usar el csv attacks_limpieza_completa que tenéis adjunto abajo.\n",
    "\n",
    "En la lección de hoy aprendimos como transformar nuestros datos para que estén preparados para almacearlos en una BBDD. En este momento tenemos dos fuentes de datos:\n",
    "\n",
    "    1. El csv con los ataques de tiburones que hemos estado limpiando hasta ahora, el que os hemos adjuntado (attacks_limpieza_completa). Sentiros libres de usar vuestros propios csv en caso de que queráis.\n",
    "\n",
    "    2. El csv con los datos climáticos de los principales paises que tienen ataques de tiburones, el que creamos en el pair programming de ayer.\n",
    "\n",
    "El objetivo de la sesión de hoy será juntar en un único csv la información de ambas fuentes. Para ello:\n",
    "\n",
    "- Cargaremos los dos ficheros de datos\n",
    "- Del dataframe de los ataques nos quedaremos solo con las filas de los países que seleccionamos en la lección de ayer:\n",
    "\n",
    "    - USA\n",
    "    - Australia\n",
    "    - New Zealand\n",
    "    - South Africa\n",
    "    - Papua New Guinea\n",
    "\n",
    "- Del dataframe de los datos climáticos seleccionaremos todas las columnas.\n",
    "\n",
    "- Cuando ya tengamos todos los datos deseados juntaremos los dos csv.\n",
    "Para hacer esta unión tendremos que hacer un groupby en la tabla de clima para sacar una media de las medidas climáticas por país.\n",
    "\n",
    "- Antes de hacer el groupby si nos fijamos tenemos dos columnas rh_profile y wind_profile cuya información es una lista de diccionarios. Si intentamos hacer la media de eso no nos dará un valor real. A este problema ya nos enfrentamos en la clase invertida de ETL-2, donde teníais un Bonus para desempaquetar esta información. En caso de que en aquel ejercicio no lo consigierais os dejamos por aquí una posible solución que nos permite separar esa información en distintas columnas. Os dejamos el código documentado. ⚠️ Os recomendamos que vayáis desgranando el código y viendo lo que nos devuelve cada línea de código para entenderlo mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os recomendamos resetear el index del dataframe \n",
    "# de los datos climáticos para que no se repitan \n",
    "# los nombres de las columnas.\n",
    "\n",
    "\n",
    "# El primer problema al que nos podemos enfrentar \n",
    "# es que si vemos los tipos de las columnas vemos \n",
    "# que estas columnas son objetos, es decir, strings,\n",
    "#  lo que hará que trabajar con ellas sea un poco \n",
    "# complicado: \n",
    "\n",
    "clima.dtypes\n",
    "\n",
    "timepoint             int64\n",
    "cloudcover            int64\n",
    "highcloud             int64\n",
    "midcloud              int64\n",
    "lowcloud              int64\n",
    "rh_profile           object\n",
    "wind_profile         object\n",
    "\n",
    "# en Python tenemos la librería `ast` que nos \n",
    "# permite castear un string que dentro tiene \n",
    "# diccionarios, o listas o tuplas a su tipo \n",
    "# correspondiente. En nuestro caso, lo que \n",
    "# conseguiremos es no tener strings sino listas \n",
    "# en la columna. Esto lo haremos de \n",
    "# la siguiente forma: \n",
    "\n",
    "import ast\n",
    "\n",
    "clima['wind_profile']= clima['wind_profile'].apply(ast.literal_eval)\n",
    "\n",
    "# una vez que tengamos la columna cambiada,\n",
    "#  una fantasía de Pandas es que si hago un\n",
    "#  apply sobre una columna cuyos valores \n",
    "# son diccionarios o listas nos va a genererar\n",
    "#  una columna con los valores de los diccionarios\n",
    "#  o listas. Donde cada columna será key \n",
    "# del diccionario o cada elemento de la lista. \n",
    "\n",
    "\n",
    "x = clima['wind_profile'].apply(pd.Series)\n",
    "\n",
    "\n",
    "# nos creamos un dataframe nuevo con el \n",
    "# resultado de la información de una de \n",
    "# las columnas separadas por columnas.\n",
    "#  Esto nos va a devolver un dataframe donde \n",
    "# cada fila será una celda del dataframe \n",
    "# anterior. \n",
    "\n",
    "x = df['rh_profile'].apply(pd.Series) \n",
    "\n",
    "# ¿Qué es lo que ocurre cuando hacemos esto?\n",
    "# Nos ha creado tantas columnas como valores \n",
    "# tuvieramos en la lista. Donde columna es,\n",
    "#  en este caso, un diccionario \n",
    "# (porque nuestra lista esta compuesta \n",
    "# por distintos diccionarios)\n",
    "\n",
    "# Ok, hemos conseguido desempaquetar \n",
    "# la información de la lista en distintas \n",
    "# columnas. Ahora tenemos que despempaquetar\n",
    "#  la información de los diccionarios en\n",
    "#  distintas columnas. En este caso, \n",
    "# lo que querremos es que las key de \n",
    "# los diccionarios sean los nombres de \n",
    "# las columnas y los values los valores \n",
    "# de las celdas del dataframe. \n",
    "# Volveremos a seguir entonces la misma lógica\n",
    "# que antes con el apply, pero en este caso \n",
    "# necesitamos hacerlo para todo el dataframe\n",
    "#  (que es x): \n",
    "\n",
    "# Por eso empezamos con un for para iterar \n",
    "# por cada una de las columnas. \n",
    "\n",
    "for i in range(len(x.columns)): \n",
    "\n",
    "    # aplicamos el apply,extraemos el valore\n",
    "    #  de la key \"layer\" y lo almacenamos en \n",
    "    # una variable que convertimos a string \n",
    "\n",
    "    nombre = \"rh_\" + str(x[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "    # hacemos lo mismo con una variable que se \n",
    "    # llame valores para \"guardar\" los valores \n",
    "    # de la celda\n",
    "\n",
    "    valores = list(x[i].apply(pd.Series)[\"rh\"] )\n",
    "\n",
    "    # usamos el método insert de los dataframes \n",
    "    # para ir añadiendo esta información a el \n",
    "    # dataframe con la información del clima. \n",
    "\n",
    "    df.insert(i, nombre, valores)\n",
    "\n",
    "# una vez que hayamos hecho esto para las dos \n",
    "# columnas ya podremos hacer el gropuby para \n",
    "# después unir toda la información. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Guardar los resultados obtenidos en un csv que usaremos en próximos ejercicios de pair programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b3ff6a27870a7cc36cfcc233c2d6d7a500b67077a2ccb041bb9f3f5f987204"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
